{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datascience import *\n",
    "%matplotlib inline\n",
    "path_data = '../../../assets/data/'\n",
    "import matplotlib.pyplot as plots\n",
    "plots.style.use('fivethirtyeight')\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=np.VisibleDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Question: Super Soda\n",
    "\n",
    "Recall the problem setup: \n",
    "\n",
    "* We observe 91/200 taste testers prefer Super Soda\n",
    "* We expected it to be 50/50 — is the observed result due to chance or do they truly not like Super Soda as much?\n",
    "    * Null: 50% of the population prefers Super Soda and 50% do not.\n",
    "    * Alternative: Less than 50% of the population prefers Super Soda.\n",
    "* Test statistic: Number of people out of 200 who prefer Super Soda\n",
    "* P-value: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Writing a function to simulate under the null hypothesis (50-50 split of Super Soda fans)\n",
    "\n",
    "def simulate_one_count(sample_size):\n",
    "    return np.count_nonzero(np.random.choice(['H', 'T'], sample_size) == 'H')\n",
    "\n",
    "simulate_one_count(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate distribution under the null hypothesis\n",
    "\n",
    "num_simulations = 10000\n",
    "counts = make_array()\n",
    "\n",
    "for i in np.arange(num_simulations):\n",
    "    counts = np.append(counts, simulate_one_count(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does the distribution under the null look like?\n",
    "\n",
    "trials = Table().with_column('Number of Heads', counts)\n",
    "trials.hist(right_end=91)\n",
    "plots.ylim(-0.001, 0.055)\n",
    "plots.scatter(91, 0, color='red', s=40, zorder=3)\n",
    "plots.title('Prediction Under the Null');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the p-value — which values support the alternative hypothesis?\n",
    "\n",
    "np.count_nonzero(counts <= 91)/len(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things that can affect the result of a hypothesis test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the number of simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping the data fixed, we can re-run the test with a new simulation under the null\n",
    "\n",
    "def run_test(num_simulations, sample_size):\n",
    "    counts = make_array()\n",
    "    for i in np.arange(num_simulations):\n",
    "        counts = np.append(counts, simulate_one_count(sample_size))\n",
    "    return counts\n",
    "\n",
    "counts = run_test(10000, 200)\n",
    "np.count_nonzero(counts <= 91)/len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying out 3 numbers of simulations: 100, 1000, 10000\n",
    "\n",
    "# We'll conduct 20 hypothesis tests at each number of simulations.\n",
    "\n",
    "tests = Table(['simulations', 'p-value for 91'])\n",
    "for num_sims in [100, 1000, 10000]:\n",
    "    for k in np.arange(20):\n",
    "        counts = run_test(num_sims, 200)\n",
    "        tests = tests.with_row([\n",
    "            num_sims, \n",
    "            np.count_nonzero(counts <= 91)/len(counts),\n",
    "        ])\n",
    "tests.group('simulations', np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For larger numbers of simulations, p-values are more consistent\n",
    "\n",
    "tests.hist(1, group='simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since a large number of simulations provides a good estimate of the\n",
    "# theoretical distribution of the test statistic under the null hypothesis\n",
    "num_sims = 10000\n",
    "counts_1 = run_test(num_sims, 200)\n",
    "counts_2 = run_test(num_sims, 200)\n",
    "t = Table().with_columns(\n",
    "    'Experiment', [1] * num_sims + [2] * num_sims,\n",
    "    'Number of Heads', np.append(counts_1, counts_2))\n",
    "t.hist(1, group='Experiment', bins=np.arange(70.5, 131, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the sample size\n",
    "\n",
    "This is different from changing the number of simulations!\n",
    "\n",
    "Let's say we're now running a taste test of 200\\*2 = 400 people. We observe that 91\\*2 = 182 of them prefer Super Soda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 10000\n",
    "counts = make_array()\n",
    "\n",
    "for i in np.arange(num_simulations):\n",
    "    counts = np.append(counts, simulate_one_count(400))\n",
    "    \n",
    "# What does the distribution under the null look like?\n",
    "\n",
    "trials = Table().with_column('Number of Heads', counts)\n",
    "trials.hist(right_end=182)\n",
    "plots.ylim(-0.001, 0.055)\n",
    "plots.scatter(182, 0, color='red', s=40, zorder=3)\n",
    "plots.title('Prediction Under the Null');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(counts <= 182)/len(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value decreased by quite a lot! Think about why this is the case. An example: It's more unusual to get 600 heads out of 1000 coin tosses than 6 heads out of 10 coin tosses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the truth about the population\n",
    "\n",
    "We'll use simulation to explore what happens when our population changes. Since we know the truth about the population, we can use this to figure out how accurate our results are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose that the true proportion of people who prefer Super Soda is 45%\n",
    "true_proportion = 0.45\n",
    "true_distribution = make_array(true_proportion, 1 - true_proportion)\n",
    "true_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taste tests with 200 people will give varioius numbers of people who prefer Super Soda\n",
    "sample_size = 200\n",
    "sample_proportions(sample_size, true_distribution) * sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you run a taste test for 200 people, what might you conclude?\n",
    "def run_experiment(num_simulations, sample_size, true_proportion):\n",
    "    # Collect data\n",
    "    true_distribution = make_array(true_proportion, 1 - true_proportion)\n",
    "    taste_test_results = sample_proportions(sample_size, true_distribution) * sample_size\n",
    "    observed_stat_from_this_sample = taste_test_results.item(0)\n",
    "    \n",
    "    # Conduct hypothesis test\n",
    "    counts = run_test(num_simulations, sample_size)\n",
    "    p_value = np.count_nonzero(counts <= observed_stat_from_this_sample) / len(counts)\n",
    "    return p_value\n",
    "\n",
    "run_experiment(10000, 200, 0.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's imagine running our taste test over and over again to see how often we reject the null\n",
    "true_proportion = 0.45\n",
    "sample_size = 200\n",
    "p_values = make_array()\n",
    "for k in np.arange(100):\n",
    "    p_value = run_experiment(10000, sample_size, true_proportion)\n",
    "    p_values = np.append(p_values, p_value)\n",
    "Table().with_column('P-value', p_values).hist(0, bins=20)\n",
    "\n",
    "# proportion of experiments where we rejected the null\n",
    "np.mean(p_values <= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's imagine running our taste test over and over again to see how often we reject the null\n",
    "true_proportion = 0.48\n",
    "sample_size = 200\n",
    "p_values = make_array()\n",
    "for k in np.arange(100):\n",
    "    p_value = run_experiment(10000, sample_size, true_proportion)\n",
    "    p_values = np.append(p_values, p_value)\n",
    "Table().with_column('P-value', p_values).hist(0, bins=20)\n",
    "\n",
    "# proportion of experiments where we rejected the null\n",
    "np.mean(p_values <= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's imagine running our taste test over and over again to see how often we reject the null\n",
    "true_proportion = 0.3\n",
    "sample_size = 200\n",
    "p_values = make_array()\n",
    "for k in np.arange(100):\n",
    "    p_value = run_experiment(10000, sample_size, true_proportion)\n",
    "    p_values = np.append(p_values, p_value)\n",
    "Table().with_column('P-value', p_values).hist(0, bins=20)\n",
    "\n",
    "# proportion of experiments where we rejected the null\n",
    "np.mean(p_values <= 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
